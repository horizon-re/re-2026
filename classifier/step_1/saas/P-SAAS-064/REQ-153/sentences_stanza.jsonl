{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s001", "order": 1, "text": "**Ticket Title:** OCR Misinterpretation of \"5 s\" as \"$5\" Leading to Price Calculation Error", "char_start": 0, "char_end": 91, "splitter": "stanza", "token_count": 21}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s002", "order": 2, "text": "**Description:**", "char_start": 93, "char_end": 109, "splitter": "stanza", "token_count": 3}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s003", "order": 3, "text": "Our OCR system is incorrectly interpreting the string \"5 s\" (representing \"5 seconds\") as \"$5\", leading to miscalculations in price-sensitive contexts where time-based data is critical.", "char_start": 112, "char_end": 297, "splitter": "stanza", "token_count": 41}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s004", "order": 4, "text": "This is especially problematic in automated billing and log analysis pipelines where time and currency are both present, creating ambiguities.", "char_start": 298, "char_end": 440, "splitter": "stanza", "token_count": 22}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s005", "order": 5, "text": "**Tasks:**", "char_start": 442, "char_end": 452, "splitter": "stanza", "token_count": 3}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s006", "order": 6, "text": "1. **Implement contextual spell-checking logic** that distinguishes between time units (e.g., \"s\", \"sec\", \"seconds\") and monetary values (e.g., \"$\", \"USD\", etc.).", "char_start": 455, "char_end": 617, "splitter": "stanza", "token_count": 47}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s007", "order": 7, "text": "This should rely on surrounding words and common patterns to infer the correct unit.", "char_start": 618, "char_end": 702, "splitter": "stanza", "token_count": 15}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s008", "order": 8, "text": "2. **Introduce a manual review flag** for any extracted value where time and currency indicators are mixed or ambiguous (e.g., \"$5s\", \"5 $s\", etc.).", "char_start": 703, "char_end": 851, "splitter": "stanza", "token_count": 39}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s009", "order": 9, "text": "3. **Update the OCR post-processing pipeline** to apply this logic before final value extraction is returned downstream.", "char_start": 852, "char_end": 972, "splitter": "stanza", "token_count": 23}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s010", "order": 10, "text": "**Acceptance Criteria:**  \n- System must correctly identify \"5 s\" as time when used in timing or duration context.", "char_start": 974, "char_end": 1088, "splitter": "stanza", "token_count": 23}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s011", "order": 11, "text": "-", "char_start": 1089, "char_end": 1090, "splitter": "stanza", "token_count": 1}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s012", "order": 12, "text": "No false positive currency values should result from timing strings.", "char_start": 1091, "char_end": 1159, "splitter": "stanza", "token_count": 11}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s013", "order": 13, "text": "- All flagged ambiguities should appear in the review dashboard with context snippet and original OCR output.", "char_start": 1160, "char_end": 1269, "splitter": "stanza", "token_count": 18}
{"doc_id": "ab61fa30-e0a3-5078-aace-22d20fa68fba", "req_id": "REQ-153", "sent_id": "REQ-153::s014", "order": 14, "text": "**Priority:** High  \n**Estimate:** 3 engineering days", "char_start": 1271, "char_end": 1324, "splitter": "stanza", "token_count": 10}
